{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Hkmq6woHCE"
      },
      "source": [
        "Please click below to open this notebook with colab.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1r3QAoLsI-k6se1EubeepUs8p0Bqvapb_?usp=sharing)\n",
        "\n",
        "The Deepchem and dataset setup below was taken from the official tutorial: [link ](https://github.com/deepchem/deepchem/blob/master/examples/tutorials/03_Modeling_Solubility.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y2I9ylVoGfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0f4389-241d-4c2b-98a0-c869c0f9b2e1"
      },
      "source": [
        "# Installing conda\n",
        "!curl -Lo conda_installer.py https://raw.githubusercontent.com/deepchem/deepchem/master/scripts/colab_install.py\n",
        "import conda_installer\n",
        "conda_installer.install()\n",
        "!/root/miniconda/bin/conda info -e"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3457  100  3457    0     0  14888      0 --:--:-- --:--:-- --:--:-- 14900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "add /root/miniconda/lib/python3.10/site-packages to PYTHONPATH\n",
            "INFO:conda_installer:add /root/miniconda/lib/python3.10/site-packages to PYTHONPATH\n",
            "python version: 3.10.6\n",
            "INFO:conda_installer:python version: 3.10.6\n",
            "fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "INFO:conda_installer:fetching installer from https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "done\n",
            "INFO:conda_installer:done\n",
            "installing miniconda to /root/miniconda\n",
            "INFO:conda_installer:installing miniconda to /root/miniconda\n",
            "done\n",
            "INFO:conda_installer:done\n",
            "installing openmm, pdbfixer\n",
            "INFO:conda_installer:installing openmm, pdbfixer\n",
            "added conda-forge to channels\n",
            "INFO:conda_installer:added conda-forge to channels\n",
            "done\n",
            "INFO:conda_installer:done\n",
            "conda packages installation finished!\n",
            "INFO:conda_installer:conda packages installation finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.19: cannot open shared object file: No such file or directory)\n",
            "# conda environments:\n",
            "#\n",
            "base                     /root/miniconda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqG_49beo8uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afe5159-00e0-4b8a-d131-3d7e3a1e1900"
      },
      "source": [
        "# Installing Deepchem\n",
        "!pip3 install --pre deepchem\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.10/dist-packages (2.7.2.dev20230730200710)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.10.1)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2023.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2022.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyopenssl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "tQhI-U15auK3",
        "outputId": "3d24c96f-d37d-4e5f-dc8b-da5d454d4355"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyopenssl\n",
            "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 (from pyopenssl)\n",
            "  Downloading cryptography-41.0.2-cp37-abi3-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl) (2.21)\n",
            "Installing collected packages: cryptography, pyopenssl\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "Successfully installed cryptography-41.0.2 pyopenssl-23.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cryptography"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AiUnBdVZtrF",
        "outputId": "c0c78c51-fc82-4811-b54b-8763f8ef0416"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with transformers dependency. No module named 'transformers'\n",
            "WARNING:deepchem.models:cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "ety_QbHBeIVg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = r\"/content/hERG_bioactivity_pIC50.csv\"\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EnJrvWingKpK",
        "outputId": "bb89802f-db27-488f-f304-e7b34f8b7ce0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/hERG_bioactivity_pIC50.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = deepchem.data.CSVLoader(tasks=[\"pIC50\"],\n",
        "                                 smiles_field=\"canonical_smiles\",\n",
        "                                 featurizer=deepchem.feat.ConvMolFeaturizer())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFhSQFexfeDn",
        "outputId": "6473b1fc-8325-42fa-b300-6d09bc3873a6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.data.data_loader:smiles_field is deprecated and will be removed in a future version of DeepChem.Use feature_field instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = loader.featurize(df)"
      ],
      "metadata": {
        "id": "WAih5xOaqPH4",
        "outputId": "f30030c6-a8c0-4b12-dd91-443e58217040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deepchem/data/data_loader.py:168: FutureWarning: featurize() is deprecated and has been renamed to create_dataset().featurize() will be removed in DeepChem 3.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Random Splitter"
      ],
      "metadata": {
        "id": "7F8tfCORhaic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitter splits the dataset\n",
        "# In this case it's is an equivalent of train_test_split from sklearn\n",
        "splitter = deepchem.splits.RandomSplitter()\n",
        "# frac_test is 0.01 because we only use a train and valid as an example\n",
        "train, valid, test = splitter.train_valid_test_split(dataset,\n",
        "                                                      frac_train=0.7,\n",
        "                                                      frac_valid=0.29,\n",
        "                                                      frac_test=0.01)\n",
        "# Normalizer will normalize y values in the dataset\n",
        "normalizer = deepchem.trans.NormalizationTransformer(transform_y=True,\n",
        "                                                         dataset=train,\n",
        "                                                         move_mean=True)\n",
        "train = normalizer.transform(train)\n",
        "valid = normalizer.transform(valid)\n",
        "test = normalizer.transform(test)"
      ],
      "metadata": {
        "id": "tHeiLe__hex8"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Size of the training data: {len(train.ids)}\")\n",
        "print(f\"Size of the validation data: {len(valid.ids)}\")\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAcBhJP5iNEC",
        "outputId": "58762130-cf1f-45fe-ce27-ac01b0f55da0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training data: 2077\n",
            "Size of the validation data: 861\n",
            "<DiskDataset X.shape: (30,), y.shape: (30, 1), w.shape: (30, 1), ids: ['Fc1ccc(N(CCNCCCc2ccccc2)c2ccc(F)cc2)cc1'\n",
            " 'CC(C)(C)c1ccc(C(O)CCCN2CCC(C(O)(c3ccccc3)c3ccccc3)CC2)cc1'\n",
            " 'COc1ccc(CN2CCC(NC(=O)c3cc(=O)c4ccc(F)cc4o3)CC2)cc1F' ...\n",
            " 'C[C@H](c1ccnc(Cl)c1)N1[C@@H]2CC[C@H]1C[C@H](Oc1cccc(C(N)=O)c1)C2'\n",
            " 'COc1cc2ccc(C#N)cc2cc1[C@@H](c1cccc(F)c1)[C@@](O)(CCN(C)C)c1cccc2ccoc12'\n",
            " 'CC[C@@H]1Sc2ccccc2O[C@@H]1c1ccc(OCCCN2CCCC2)cc1'], task_names: ['pIC50']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GraphConvModel is a GNN model based on\n",
        "# Duvenaud, David K., et al. \"Convolutional networks on graphs for\n",
        "# learning molecular fingerprints.\"\n",
        "from deepchem.models import GraphConvModel\n",
        "graph_conv = GraphConvModel(1,\n",
        "                            batch_size=50,\n",
        "                            mode=\"regression\")\n",
        "# Defining metric. Closer to 1 is better\n",
        "metric = deepchem.metrics.Metric(deepchem.metrics.pearson_r2_score)"
      ],
      "metadata": {
        "id": "_ACK_HLFiQSZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the model\n",
        "graph_conv.fit(train, nb_epoch=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QooapqaumulS",
        "outputId": "838aa678-4820-4588-c166-e7f4aa97b8b9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06582967827959758"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reversing the transformation and getting the metric scores on 2 datasets\n",
        "train_scores = graph_conv.evaluate(train, [metric], [normalizer])\n",
        "valid_scores = graph_conv.evaluate(valid, [metric], [normalizer])\n",
        "test_scores = graph_conv.evaluate(test, [metric], [normalizer])\n",
        "print(f\"Train Scores: {train_scores}\")\n",
        "print(f\"Validation Scores: {valid_scores}\")\n",
        "print(f\"Test Scores: {test_scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3APBLojVg-",
        "outputId": "e82754f3-2d09-468d-bf29-8a626b9090f2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Scores: {'pearson_r2_score': 0.949459289695439}\n",
            "Validation Scores: {'pearson_r2_score': 0.656088669990449}\n",
            "Test Scores: {'pearson_r2_score': 0.8579418751698057}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducing Scaffold splitter"
      ],
      "metadata": {
        "id": "BlYj4XKZdVAJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xDbW2A4p0l8"
      },
      "source": [
        "    # Splitter splits the dataset\n",
        "    # In this case it's is an equivalent of train_test_split from sklearn\n",
        "    splitter = deepchem.splits.ScaffoldSplitter()\n",
        "    # frac_test is 0.01 because we only use a train and valid as an example\n",
        "    train, valid, test = splitter.train_valid_test_split(dataset,\n",
        "                                                      frac_train=0.7,\n",
        "                                                      frac_valid=0.29,\n",
        "                                                      frac_test=0.01)\n",
        "    # Normalizer will normalize y values in the dataset\n",
        "    normalizer = deepchem.trans.NormalizationTransformer(transform_y=True,\n",
        "                                                         dataset=train,\n",
        "                                                         move_mean=True)\n",
        "    train = normalizer.transform(train)\n",
        "    valid = normalizer.transform(valid)\n",
        "    test = normalizer.transform(test)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRJfuytXJacS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ac5fbc-784a-4437-d521-fd49ca8aeda8"
      },
      "source": [
        "print(f\"Size of the training data: {len(train.ids)}\")\n",
        "print(f\"Size of the validation data: {len(valid.ids)}\")\n",
        "print(test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training data: 2077\n",
            "Size of the validation data: 861\n",
            "<DiskDataset X.shape: (30,), y.shape: (30, 1), w.shape: (30, 1), ids: ['CN(C(=O)CC[C@@H](C1CCCCC1)N1Cc2cc(Oc3ccccc3)ccc2N=C1N)C1CCCCC1'\n",
            " 'N[C@H]1CN(c2ccn3cnnc3n2)CC[C@@H]1c1cc(F)c(F)cc1F.O=C(O)C(F)(F)F'\n",
            " 'N[C@H]1CN(c2ccc3nc(=O)ccn3n2)CC[C@@H]1c1cc(F)c(F)cc1F.O=C(O)C(F)(F)F'\n",
            " ... 'CS(=O)(=O)Nc1ccc2c(c1)C(=O)CC1(CCN(CCc3ccc4nonc4c3)CC1)O2'\n",
            " 'CN(C)CCCn1nc(C2=C(c3cn(-c4ccc5ccccc5c4)c4ccccc34)C(=O)NC2=O)c2ccccc21'\n",
            " 'CN(C)CCN1C(=O)C(NC(=O)CCc2ccc(Cl)cc2Cl)N=C(c2ccccc2)c2ccccc21'], task_names: ['pIC50']>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NKyzDA-JlXY"
      },
      "source": [
        "# GraphConvModel is a GNN model based on\n",
        "# Duvenaud, David K., et al. \"Convolutional networks on graphs for\n",
        "# learning molecular fingerprints.\"\n",
        "from deepchem.models import GraphConvModel\n",
        "graph_conv = GraphConvModel(1,\n",
        "                            batch_size=50,\n",
        "                            mode=\"regression\")\n",
        "# Defining metric. Closer to 1 is better\n",
        "metric = deepchem.metrics.Metric(deepchem.metrics.pearson_r2_score)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HRwydQ0K34F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82deee9-6061-4e80-aa21-082c08a5f38d"
      },
      "source": [
        "# Fitting the model\n",
        "graph_conv.fit(train, nb_epoch=40)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10503836870193481"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMrQHy7ELE1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9bb72f-3f22-4be2-eb9f-95ad39d563c5"
      },
      "source": [
        "# Reversing the transformation and getting the metric scores on 2 datasets\n",
        "train_scores = graph_conv.evaluate(train, [metric], [normalizer])\n",
        "valid_scores = graph_conv.evaluate(valid, [metric], [normalizer])\n",
        "test_scores = graph_conv.evaluate(test, [metric], [normalizer])\n",
        "print(f\"Train Scores: {train_scores}\")\n",
        "print(f\"Validation Scores: {valid_scores}\")\n",
        "print(f\"Test Scores: {test_scores}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Scores: {'pearson_r2_score': 0.9107839407669827}\n",
            "Validation Scores: {'pearson_r2_score': 0.3206801291348099}\n",
            "Test Scores: {'pearson_r2_score': 0.1780441434805936}\n"
          ]
        }
      ]
    }
  ]
}